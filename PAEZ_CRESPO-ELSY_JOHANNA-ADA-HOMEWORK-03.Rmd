---
title: "PAEZ_CERSPO-ELSY_JOHANNA-ADA-HOMEWORK-03"
author: "Johanna Paez Crespo"
date: "20/3/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<span style="color:blue">***PROBLEM-01:***</span>

Write a simple R function you call Z.prop.test(), that can perform one- or two-sample Z-tests for proportion data, using the following guidelines.

- Your function should take the following arguments: p1 and n1 (no default) representing the estimated proportion and sample size (e.g., based on your sample data); p2 and n2 (both defaulting to NULL) that contain a second sample’s proportion and sample size data in the event of a two-sample test; p0 (no default) as the expected value for the population proportion; and alternative (default “two.sided”) and conf.level (default 0.95), to be used in the same way as in the function t.test().
- When conducting a two-sample test, it should be p1 that is tested as being smaller or larger than p2 when alternative=“less” or alternative=“greater”, respectively, the same as in the use of x and y in the function t.test().
- The function should perform a one-sample Z-test using p1, n1, and p0 if either p2 or n2 (or both) is NULL.
- The function should contain a check for the rules of thumb we have talked about (n×π>5 and n×(1−π)>5) to ensure the validity of assuming the normal distribution in both the one- and two-sample settings. If this is violated, the function should still complete, but it should also print an appropriate warning message.
- The function should return a list containing the following elements: Z (the test statistic), P (the appropriate p value), and CI (the two-sided CI with respect to “conf.level” around p1 in the case of a one-sample test and around p2-p1 in the case of a two-sample test). For all test alternatives (“two.sided”, “greater”, “less”), calculate symmetric CIs based on quantiles of the normal distribution rather than worrying about calculating single-limit confidence bounds.

####CODING for one-sample Z-test:

```{r}
z.prop.test <- function(p1, p2 = NULL, n1, n2 = NULL, p0, alternative = "less", conf.level = 0.95){
  # Coding for one-sample Z-test:
  if(is.null(p2)){
    p1 <- mean(v1)
    n1 <- length(v1)
    p0 <- # expected proportion
    z <- (p1 - p0)/sqrt(p0 * (1 - p0) / n1)
    p <- pnorm(z, lower.tail = TRUE)
    lower.ci <- p1 - qnorm(conf.level) * sqrt(p1 * (1 - p1)/n1)
    upper.ci <- p1 + qnorm(conf.level) * sqrt(p1 * (1 - p1)/n1)
     if((n1*p1)>5 && (n1*(1-p1)) > 5){
       message("Validation: Be careful! The assumption of normal distribution is violated!")
       }
    else{
      message("Validation: Data are normally distributed!")
    }
  outcome <- list(z, p, lower.ci, upper.ci)
  names(outcome) <- c("z", "p", "lower.ci", "upper.ci")
  }
outcome
}
```

####CODING for two-sample Z-test:

```{r}
z.prop.test <- function(p1, p2, n1, n2, p0=0, alternative = "two.sided", conf.level = 0.95){
  # Coding for two-sample Z-test:
  {
    p1 <- mean(v1)
    p2 <- mean(v2)
    n1 <- length(v1)
    n2 <- length(v2)
    pstar <- (sum(v1) + sum(v2)) / (length(v1) + length(v2))
    z <- (p2 - p1)/sqrt((pstar * (1 - pstar)) * (1/length(v1) + 1/length(v2)))
    p.upper <- 1 - pnorm(z, lower.tail = TRUE) 
    p.lower <- pnorm(z, lower.tail = FALSE)
    p <- p.upper + p.lower
    lower.ci <- (p2 - p1) - 1.96 * sqrt(((p1 * (1 - p1))/n1) + ((p2 * (1 - p2))/n2)) # Assuming a normal distribution, we can state that 95% of the sample mean would lie within 1.96 SEs above or below the popualtion mean, since 1.96 is the 2-sides 5% point of the standard normal distribution.
    upper.ci <- (p2 - p1) + 1.96 * sqrt(((p1 * (1 - p1))/n1) + ((p2 * (1 - p2))/n2))
     if((n1*p1)>5 && (n1*(1-p1)) > 5){
       message("Validation: Be careful! The assumption of normal distribution is violated!")
       }
    else{
      message("Validation: Data are normally distributed!")
    }
  outcome1 <- list(z, p, lower.ci, upper.ci)
  names(outcome1) <- c("z", "p", "lower.ci", "upper.ci")
  }
outcome1
}
```

<span style="color:blue">***PROBLEM-02:***</span>

The comparative primate dataset we have used from Kamilar and Cooper has in it a large number of variables related to life history and body size. For this exercise, the end aim is to fit a simple linear regression model to predict longevity (MaxLongevity_m) measured in months from species’ brain size (Brain_Size_Species_Mean) measured in grams. Do the following for both longevity~brain size and log(longevity)~log(brain size).

```{r}
library(readr)
library(tidyverse)
library(curl)
f <- curl("https://raw.githubusercontent.com/difiore/ADA-2019/master/KamilarAndCooperData.csv")
d <- read.csv(f, header = TRUE, stringsAsFactors = FALSE)
names(d)
```

a) Fit the regression model and, using {ggplot2}, produce a scatterplot with the fitted line superimposed upon the data. Append the fitted model equation to your plot (HINT: use the function geom_text()).

en formula lm(dependiente ~ independiente)
Longevity ~ BrainSize

####LONGEVITY ~ BRAIN SIZE
 
```{r}
library(ggplot2)
Longevity <- c(d$MaxLongevity_m)
BrainSize <- c(d$Brain_Size_Species_Mean)
m <- lm(data=d, Longevity ~ BrainSize)
m$coefficients
```

```{r}
g <- ggplot(data=d, aes(x=BrainSize, y=Longevity))
g <- g + labs(subtitle="Longevity ~ Brain Size")
g <- g + geom_point()
g <- g + geom_smooth(method = "lm", formula = y ~ x)
g <- g + geom_text(x=350, y=300,  label="y=1.218x + 248.952", color="blue")
g
```

####Log(LONGEVITY) ~ Log(BRAIN SIZE)

```{r}
LogLon <- log(Longevity)
LogBraSize <- log(BrainSize)
m1 <- lm(data=d, LogLon ~ LogBraSize)
m1$coefficients
```

```{r}
g <- ggplot(data=d, aes(x=LogBraSize, y=LogLon))
g <- g + labs(subtitle="Log(Longevity) ~ Log(Brain Size)", x="Log(Brain Size)", y="Log(Longevity)")
g <- g + geom_point()
g <- g + geom_smooth(method = "lm", formula = y ~ x)
g <- g + geom_text(x=1.7, y=6.3,  label="y=0.2341x + 4.8790", color="blue")
g
```

b) Identify and interpret the point estimate of the slope (β1), as well as the outcome of the test associated with the hypotheses H0: β1=0; HA: β1≠0. Also, find a 90% CI for the slope (β1) parameter.

####LONGEVITY ~ BRAIN SIZE
B1 <- 1.218

B0 <- 248.952

<span style="color:green">***Interpretation:***</span>
For every 1 unit of change in Brain Size (x), we expected a 1.218 change in Longevity. Adittionally, B1 is not equal to zero (0), which means that we reject the null hypothesis, which support a effect of Brain Size on Longevity

```{r}
alpha <- 0.1
ci_lm <- confint(m, level = 1 - alpha)
ci_lm
```

####Log(LONGEVITY) ~ Log(BRAIN SIZE)

B1 <- 0.2341

B0 <- 4.8790

<span style="color:green">***Interpretation:***</span>
For every 1 unit of change in Log(Brain Size) (x), we expected a 0.2341 change in Log(Longevity). Adittionally, B1 is not equal to zero (0), which means that we reject the null hypothesis, which support a effect of Log(Brain Size) on Log(Longevity)

```{r}
alpha <- 0.1
ci_lm1 <- confint(m1, level = 1 - alpha)
ci_lm1
```

c) Using your model, add lines for the 90% confidence and prediction interval bands on the plot, and add a legend to differentiate between the lines.

####LONGEVITY ~ BRAIN SIZE
```{r}
m <- lm(data=d, Longevity ~ BrainSize)
Longevity_hat <- predict(m, newdata = data.frame(BrainSize = d$Brain_Size_Species_Mean))
df <- data.frame(cbind(d$Brain_Size_Species_Mean, d$MaxLongevity_m, Longevity_hat))
names(df) <- c("x", "y", "yhat")
head(df)
```

```{r}
ci <- predict(m, newdata = data.frame(BrainSize = d$Brain_Size_Species_Mean), interval = "confidence", level = 0.90)  # for a vector of values
head(ci)
```

```{r}
pi <- predict(m, newdata = data.frame(BrainSize = d$Brain_Size_Species_Mean), interval = "prediction", level = 0.90)  # for a vector of values
head(pi)
```

```{r}
dff <- cbind(df, ci, pi)
names(dff) <- c("x", "y", "yhat", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr", 
    "PIupr")
head(dff)
```

```{r}
g <- ggplot(data = dff, aes(x = x, y = y))
g <- g + geom_point(alpha = 0.5)
g <- g + geom_line(aes(x = x, y = CIfit), colour = "black")
g <- g + geom_line(aes(x = x, y = CIlwr), colour = "blue")
g <- g + geom_line(aes(x = x, y = CIupr), colour = "blue")
g <- g + geom_line(data = dff, aes(x = x, y = PIlwr), colour = "red")
g <- g + geom_line(data = dff, aes(x = x, y = PIupr), colour = "red")
g <- g + scale_color_manual(labels=c("Predicted", "hah"), values=c("blue", "red")) + guides(color=guide_legend("my data"))
g
```

####Log(LONGEVITY) ~ Log(BRAIN SIZE)
```{r}
```

d) Produce a point estimate and associated 90% prediction interval for the longevity of a species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?

```{r}
```

e) Looking at your two models, which do you think is better? Why?
